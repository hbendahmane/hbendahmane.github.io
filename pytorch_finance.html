<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>PyTorch - Neural Model for Sequential Financial Feature Processing - Hamza Bendahmane</title>
<link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&display=swap" rel="stylesheet">
<style>
body {
  font-family: 'Merriweather', serif;
  margin: 0;
  padding: 0;
  color: #ffffff;
  overflow-x: hidden;
  background-color: #0a1f44;
}
.container { display: flex; min-height: 100vh; }
.sidebar { width: 25%; min-width: 220px; background: url("earth-11595(1).jpg") no-repeat center center; background-size: cover; position: fixed; top: 0; right: -25%; height: 100%; padding: 20px; box-sizing: border-box; transition: right 1s ease-in-out; color: #ffffff; display: flex; flex-direction: column; justify-content: flex-start; z-index: 2; }
.sidebar::before { content: ""; position: absolute; inset: 0; background: rgba(0,0,0,0.55); z-index: -1; }
.sidebar.active { right: 0; }
.sidebar h1 { font-size: 2.2em; margin-bottom: 8px; }
.sidebar h2 { font-size: 1em; margin-bottom: 20px; font-weight: 400; }
.sidebar blockquote { font-style: italic; font-size: 1em; line-height: 1.4; margin-bottom: 20px; color: #ffffff; }
.sidebar nav { display: flex; flex-direction: column; }
.sidebar nav a { margin-bottom: 10px; text-decoration: none; color: #ffffff; font-weight: bold; font-size: 0.95em; }
.sidebar nav a.current { opacity: 0.5; pointer-events: none; }
.sidebar nav a:hover:not(.current) { text-decoration: underline; }

.content { margin-right: 25%; width: 75%; padding: 60px 40px; opacity: 0; transition: opacity 1s ease-in-out; min-height: 100vh; box-sizing: border-box; }
.content.active { opacity: 1; }

.back-link { font-weight: 700; color: #ffffff; text-decoration: none; display: inline-block; margin-bottom: 20px; }
.back-link::before { content: "← "; }

h1.page-title { font-size: 2em; margin-bottom: 6px; }
h2.section-title { font-size: 1.3em; margin-top: 30px; margin-bottom: 10px; color: #ffffff; }
p.section-text { font-size: 1em; line-height: 1.6; margin-bottom: 20px; color: #ffffff; }

/* Terminal block */
.terminal-header { font-weight: 700; font-size: 1.1em; margin-bottom: 6px; }
.terminal-block { background-color: #101f3b; border-radius: 8px; padding: 15px; font-family: monospace; white-space: pre-wrap; overflow-x: auto; color: #cfcfcf; margin-bottom: 30px; }

/* Footnote indices */
sup a { font-size:0.95em; font-family: inherit; vertical-align: super; color: #ffffff; text-decoration: none; }
sup a:hover { text-decoration: underline; }
</style>
</head>
<body>
<div class="container">

  <div class="content" id="content">
    <main>
      <a href="code.html" class="back-link">Back to Code and Software Demo</a>
      <h1 class="page-title">PyTorch – Neural Model for Sequential Financial Feature Processing</h1>

      <h2 class="section-title">Goal</h2>
      <p class="section-text">
        The objective of this module is to demonstrate a clean, production-aligned inference pipeline for an AI-driven trading signal generator. 
        The goal is to structure a neural model capable of processing sequential market features and outputting three key metrics expected in a quantitative decision system: directional probabilities (Short / Neutral / Long), a confidence score to scale exposure, and a risk estimate to constrain position sizing. 
        This positions the code as a foundation for a future learning-based trading engine while remaining lightweight and deterministic for demonstration and integration purposes.
      </p>

      <h2 class="section-title">Engineering Approach and Tools</h2>
      <p class="section-text">
        The implementation uses PyTorch to define a GRU-based neural network that processes sequences of synthetic feature vectors. 
        The model architecture includes an input encoder layer, a recurrent GRU block for temporal pattern extraction, and three dedicated output heads. 
        Each head produces a specific signal component with appropriate activation functions: Softmax for direction probabilities, Sigmoid for confidence scaling, and Softplus for positive risk estimation. 
        Data is generated using random tensors to simulate a batch of market sequences, and the model is executed in inference mode without parameter updates. 
        The inference output is then packaged and the model is exported to ONNX, enabling compatibility with deployment environments and real-time execution engines.
      </p>

      <h2 class="section-title">Execution Behavior and Output Interpretation</h2>
      <p class="section-text">
        The execution produces structured outputs for a batch of five simulated sequences. 
        The direction probabilities tensor shows a balanced distribution across Short, Neutral, and Long states, confirming consistent Softmax normalization. 
        The confidence values remain close to 0.5, indicating neutral conviction due to the absence of trained weights. 
        The risk estimate output returns positive scalar values around 0.59–0.60, as enforced by the Softplus activation. 
        These outputs confirm that the architecture is functioning correctly, forward propagation is valid, and the model produces coherent tensors ready for downstream consumption in a trading pipeline or ONNX runtime environment.
      </p>

      <h2 class="section-title">Code</h2>
      <div class="terminal-block">
      import torch
import torch.nn as nn
import torch.nn.functional as F
import os


# AI Model
# -----------------------------
class QuantTradingAI(nn.Module):
    """
    Deep learning model for quantitative trading.
    
    Features:
    - Sequence encoding via GRU
    - Multi-head outputs: direction, confidence, risk
    """
    def __init__(self, feature_dim=256, hidden_dim=128, seq_len=60, num_assets=4):
        super().__init__()
        self.seq_len = seq_len
        self.feature_dim = feature_dim
        self.hidden_dim = hidden_dim
        self.num_assets = num_assets

        # Input encoding
        self.input_encoder = nn.Linear(feature_dim, hidden_dim)

        # GRU sequence model
        self.gru = nn.GRU(
            input_size=hidden_dim,
            hidden_size=hidden_dim,
            num_layers=1,
            batch_first=True
        )

        # Multi-head outputs
        self.direction_head = nn.Linear(hidden_dim, 3)
        self.confidence_head = nn.Linear(hidden_dim, 1)
        self.risk_head = nn.Linear(hidden_dim, 1)

    def forward(self, seq_features):
        x = F.relu(self.input_encoder(seq_features))
        gru_out, _ = self.gru(x)
        last_hidden = gru_out[:, -1, :]
        direction_logits = self.direction_head(last_hidden)
        direction_probs = F.softmax(direction_logits, dim=-1)
        confidence = torch.sigmoid(self.confidence_head(last_hidden))
        risk = F.softplus(self.risk_head(last_hidden))
        return {
            "direction_probs": direction_probs,
            "confidence": confidence,
            "risk": risk
        }


# Loss
# -----------------------------
class TradingLoss(nn.Module):
    def __init__(self, risk_penalty=0.1):
        super().__init__()
        self.risk_penalty = risk_penalty

    def forward(self, predictions, targets, portfolio_returns):
        direction_loss = F.cross_entropy(predictions['direction_probs'], targets)
        risk_adjusted_loss = - (portfolio_returns.mean() / (predictions['risk'] + 1e-6))
        return direction_loss + self.risk_penalty * risk_adjusted_loss


# ONNX Export
# -----------------------------
def export_onnx(model, export_path="trading_ai.onnx", seq_len=60, feature_dim=256):
    """
    Export model to ONNX with fixed shapes for clean export.
    """
    model.eval()
    dummy_input = torch.randn(1, seq_len, feature_dim)
    torch.onnx.export(
        model,
        dummy_input,
        export_path,
        input_names=["seq_features"],
        output_names=["direction_probs", "confidence", "risk"],
        opset_version=18,
        dynamic_axes=None,
        verbose=False
    )
    print(f"[ONNX] Clean export → {export_path}")


# Demo
# -----------------------------
def demo_run():
    model = QuantTradingAI()
    model.eval()
    batch_size = 5
    seq_len = 60
    feature_dim = 256
    seq_features = torch.randn(batch_size, seq_len, feature_dim)
    outputs = model(seq_features)
    print("[Demo] Trading AI outputs:")
    print("Direction probabilities:\n", outputs['direction_probs'])
    print("Confidence:\n", outputs['confidence'])
    print("Risk estimate:\n", outputs['risk'])
    export_onnx(model)

if __name__ == "__main__":
    demo_run()

      </div>

    </main>
  </div>

  <div class="sidebar" id="sidebar">
    <h1>Hamza Bendahmane</h1>
    <h2>French state-accredited Engineer (CTI) – Diplôme d’Ingénieur, MSc</h2>
    <blockquote>“Excellence, fighting spirit, and tenacity to tackle the world’s engineering challenges.”</blockquote>
    <nav>
      <a href="about.html">About</a>
      <a href="education.html">Education</a>
      <a href="projects.html">Experiences and Projects</a>
      <a href="code.html" class="current">Code and Software Demo</a>
      <a href="publications.html">Publications</a>
      <a href="skills.html">Skills</a>
    </nav>
  </div>

</div>

<script>
window.addEventListener('load', () => {
  const sidebar = document.getElementById('sidebar');
  const content = document.getElementById('content');
  content.classList.add('active');
  if (!sessionStorage.getItem('visitedHome')) {
    sidebar.classList.add('active');
    sessionStorage.setItem('visitedHome', 'true');
  } else { sidebar.style.right='0'; }
});
</script>

</body>
</html>
